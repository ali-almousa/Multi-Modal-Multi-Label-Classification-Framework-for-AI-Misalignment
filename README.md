# Multi-Modal-Multi-Label-Classification-Framework-for-AI-Misalignment

![image](https://github.com/ali-almousa/Multi-Modal-Multi-Label-Classification-Framework-for-AI-Misalignment/assets/64105031/595d9007-c554-4e12-817e-b1dec03d911a)


The rapid advancement of AI technologies, especially
within the realm of generative models such as large lan-
guage models (LLMs) and image generation systems, has
raised concerns about their potential for misuse and harm.
To address this, we propose Guardiana, a novel multi-modal
framework for detecting and preventing the generation of
unsafe or misaligned content. Guardiana integrates a multi-
label text classifier and image-to-text modules, enabling a
comprehensive analysis of both textual and visual inputs.
SK: Maybe add a sentence about image to text model as
well The text classifier is based on fine-tuned Transformer
models that can identify diverse harm categories defined
by the users. Qualitative results demonstrate Guardianaâ€™s
ability to accurately flag malicious image and text content,
including problematic LLM-generated text. The framework
represents an important step toward curbing generative AI
misuse through comprehensive input and output filtering.
Overall, Guardiana offers a flexible solution for promoting
the safe and ethical use of AI generative models across dif-
ferent modalities. Our code is made publicly available.
